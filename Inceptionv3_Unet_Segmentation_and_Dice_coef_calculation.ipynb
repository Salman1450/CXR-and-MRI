{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salman1450/CXR-and-MRI/blob/main/Inceptionv3_Unet_Segmentation_and_Dice_coef_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD4OOghXVFXz",
        "outputId": "99f38c22-62aa-47c3-a9d1-46b8bcc372c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.5 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.4.4+cuda11.cudnn82 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.4.4 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.5/312.5 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q segmentation-models\n",
        "!pip install -q tensorflow==2.5\n",
        "!pip install -q keras==2.2.4\n",
        "# !pip install -q tensorflow-estimator==2.2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1jHhizzvZg5",
        "outputId": "ce508e9c-8116-46de-f0cf-afd396657b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown --id 1CWP7QYdX-Y67FrFF0XG36SThtIOX7-dC\n",
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive('Tumor_seg.zip')"
      ],
      "metadata": {
        "id": "iLUgZg1JVRC2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "42937b5f-7a1b-401c-d313-b985b356ad31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.4\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CWP7QYdX-Y67FrFF0XG36SThtIOX7-dC\n",
            "To: /content/Tumor_seg.zip\n",
            "100% 332M/332M [00:01<00:00, 202MB/s]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "patool: Extracting Tumor_seg.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_9_u8ljv6 -- Tumor_seg.zip\n",
            "patool: ... Tumor_seg.zip extracted to `Segmentation'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Segmentation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Reshape,Input\n",
        "from tensorflow import float32\n",
        "\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "jOVlwBNGcP54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "\"\"\" Global parameters \"\"\"\n",
        "H = 256\n",
        "W = 256\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_dataset(path, split=0.2):\n",
        "    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
        "    \n",
        "    split_size = int(len(images) * split)\n",
        "    \n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
        "    x = cv2.resize(x, (W, H))   ## (h, w)\n",
        "    x = x / 255.0               ## (h, w)\n",
        "    x = x.astype(np.float32)    ## (h, w)\n",
        "    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(10)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "l-tcPgrheESS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory for storing files \"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    batch_size = 16\n",
        "    lr = 1e-4\n",
        "    num_epochs = 30\n",
        "    model_path = os.path.join(\"files\", \"inception_Unet_model.h5\")\n",
        "    csv_path = os.path.join(\"files\", \"inception_UNET_data.csv\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    dataset_path = \"/content/Segmentation\"\n",
        "    images = sorted(glob(os.path.join(dataset_path, \"images\", \"*.png\")))\n",
        "    print(type(images))\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
        "    print(type(train_x))\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "    print(f\"Test : {len(test_x)} - {len(test_y)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    BACKBONE = 'inceptionv3'\n",
        "    model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
        "    metrics = [dice_coef, iou, Recall(), Precision()]\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[\"accuracy\",metrics])\n",
        "    model.summary()"
      ],
      "metadata": {
        "id": "McilgrMwgE2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37cffbed-2893-476b-c4eb-cc850cc0e207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "Train: 1852 - 1852\n",
            "Valid: 616 - 616\n",
            "Test : 616 - 616\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 9s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, None, None, 3 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, None, None, 3 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 6 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, None, None, 6 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 8 5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 8 240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 8 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 1 138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 1 576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 9 55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 4 144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 9 288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 4 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 9 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, None, None, 1 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 6 76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 9 82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 3 6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 6 192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 6 192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 3 96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 3 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 9 55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 4 144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 9 288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 4 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 9 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 6 76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 9 82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 6 192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 6 192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 6 192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 6 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 6 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 9 55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 4 144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 9 288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 4 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 9 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 6 76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 9 82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 6 192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 6 192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 6 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 6 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 6 192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 6 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 9 55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 9 288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 9 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 9 82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 3 1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 3 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 1 384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 1 114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 1 384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 1 114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 1 172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 1 172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 1 576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 1 576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 1 576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 1 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 1 179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 1 480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 1 179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 1 215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 1 576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 1 179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 1 480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 1 215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 1 576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 1 258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 1 258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 1 576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, None, None, 1 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 3 552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 1 331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 3 960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, None, None, 3 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, None, None, 4 1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, None, None, 4 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, None, None, 3 1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, None, None, 3 1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, None, None, 3 1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, None, None, 3 0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, None, None, 3 442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, None, None, 3 442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, None, None, 3 960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, None, None, 1 576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, None, None, 3 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, None, None, 7 0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, None, None, 1 0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, None, None, 4 1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, None, None, 4 0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, None, None, 3 1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, None, None, 3 1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, None, None, 3 1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, None, None, 3 0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, None, None, 3 442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, None, None, 3 442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, None, None, 3 960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, None, None, 1 576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, None, None, 3 0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, None, None, 1 0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsampling (UpSa (None, None, None, 2 0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_concat (Concaten (None, None, None, 2 0           decoder_stage0_upsampling[0][0]  \n",
            "                                                                 mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 6488064     decoder_stage0_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_concat (Concaten (None, None, None, 5 0           decoder_stage1_upsampling[0][0]  \n",
            "                                                                 mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 626688      decoder_stage1_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_concat (Concaten (None, None, None, 3 0           decoder_stage2_upsampling[0][0]  \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 184320      decoder_stage2_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, None, None, 1 145         decoder_stage4b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, None, None, 1 0           final_conv[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 29,933,105\n",
            "Trainable params: 29,896,689\n",
            "Non-trainable params: 36,416\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=False),\n",
        "    ]\n",
        "\n",
        "model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqwdGC-Ss_rm",
        "outputId": "a9a9bf24-d063-4f74-a146-a42bba011020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "116/116 [==============================] - 77s 422ms/step - loss: 0.8926 - accuracy: 0.8554 - dice_coef: 0.1075 - iou: 0.0573 - recall: 0.9242 - precision: 0.1044 - val_loss: 0.9299 - val_accuracy: 0.7330 - val_dice_coef: 0.0702 - val_iou: 0.0364 - val_recall: 0.9822 - val_precision: 0.0571\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.92989, saving model to files/inception_Unet_model.h5\n",
            "Epoch 2/30\n",
            "116/116 [==============================] - 42s 359ms/step - loss: 0.7088 - accuracy: 0.9799 - dice_coef: 0.2914 - iou: 0.1732 - recall: 0.9036 - precision: 0.4817 - val_loss: 0.7679 - val_accuracy: 0.9634 - val_dice_coef: 0.2322 - val_iou: 0.1317 - val_recall: 0.9570 - val_precision: 0.3102\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.92989 to 0.76789, saving model to files/inception_Unet_model.h5\n",
            "Epoch 3/30\n",
            "116/116 [==============================] - 41s 357ms/step - loss: 0.4589 - accuracy: 0.9909 - dice_coef: 0.5412 - iou: 0.3748 - recall: 0.8757 - precision: 0.7192 - val_loss: 0.4996 - val_accuracy: 0.9901 - val_dice_coef: 0.5013 - val_iou: 0.3359 - val_recall: 0.8155 - val_precision: 0.6848\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.76789 to 0.49964, saving model to files/inception_Unet_model.h5\n",
            "Epoch 4/30\n",
            "116/116 [==============================] - 42s 365ms/step - loss: 0.2942 - accuracy: 0.9936 - dice_coef: 0.7058 - iou: 0.5475 - recall: 0.8667 - precision: 0.8241 - val_loss: 0.3422 - val_accuracy: 0.9916 - val_dice_coef: 0.6587 - val_iou: 0.4927 - val_recall: 0.8099 - val_precision: 0.7419\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.49964 to 0.34215, saving model to files/inception_Unet_model.h5\n",
            "Epoch 5/30\n",
            "116/116 [==============================] - 43s 372ms/step - loss: 0.2103 - accuracy: 0.9947 - dice_coef: 0.7897 - iou: 0.6539 - recall: 0.8753 - precision: 0.8679 - val_loss: 0.2624 - val_accuracy: 0.9933 - val_dice_coef: 0.7388 - val_iou: 0.5875 - val_recall: 0.7943 - val_precision: 0.8205\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.34215 to 0.26237, saving model to files/inception_Unet_model.h5\n",
            "Epoch 6/30\n",
            "116/116 [==============================] - 41s 353ms/step - loss: 0.1665 - accuracy: 0.9954 - dice_coef: 0.8335 - iou: 0.7155 - recall: 0.8828 - precision: 0.8928 - val_loss: 0.2378 - val_accuracy: 0.9937 - val_dice_coef: 0.7632 - val_iou: 0.6194 - val_recall: 0.7529 - val_precision: 0.8683\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.26237 to 0.23781, saving model to files/inception_Unet_model.h5\n",
            "Epoch 7/30\n",
            "116/116 [==============================] - 42s 359ms/step - loss: 0.1377 - accuracy: 0.9959 - dice_coef: 0.8623 - iou: 0.7587 - recall: 0.8910 - precision: 0.9106 - val_loss: 0.2132 - val_accuracy: 0.9940 - val_dice_coef: 0.7881 - val_iou: 0.6527 - val_recall: 0.7658 - val_precision: 0.8785\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.23781 to 0.21322, saving model to files/inception_Unet_model.h5\n",
            "Epoch 8/30\n",
            "116/116 [==============================] - 41s 355ms/step - loss: 0.1187 - accuracy: 0.9962 - dice_coef: 0.8813 - iou: 0.7885 - recall: 0.8954 - precision: 0.9252 - val_loss: 0.1986 - val_accuracy: 0.9940 - val_dice_coef: 0.8027 - val_iou: 0.6724 - val_recall: 0.7906 - val_precision: 0.8621\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.21322 to 0.19858, saving model to files/inception_Unet_model.h5\n",
            "Epoch 9/30\n",
            "116/116 [==============================] - 43s 368ms/step - loss: 0.1039 - accuracy: 0.9965 - dice_coef: 0.8961 - iou: 0.8122 - recall: 0.9042 - precision: 0.9339 - val_loss: 0.1984 - val_accuracy: 0.9939 - val_dice_coef: 0.8026 - val_iou: 0.6721 - val_recall: 0.7750 - val_precision: 0.8664\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.19858 to 0.19839, saving model to files/inception_Unet_model.h5\n",
            "Epoch 10/30\n",
            "116/116 [==============================] - 43s 371ms/step - loss: 0.0926 - accuracy: 0.9968 - dice_coef: 0.9075 - iou: 0.8310 - recall: 0.9102 - precision: 0.9412 - val_loss: 0.1940 - val_accuracy: 0.9937 - val_dice_coef: 0.8069 - val_iou: 0.6787 - val_recall: 0.8023 - val_precision: 0.8364\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.19839 to 0.19397, saving model to files/inception_Unet_model.h5\n",
            "Epoch 11/30\n",
            "116/116 [==============================] - 43s 369ms/step - loss: 0.0841 - accuracy: 0.9970 - dice_coef: 0.9159 - iou: 0.8451 - recall: 0.9148 - precision: 0.9478 - val_loss: 0.1862 - val_accuracy: 0.9943 - val_dice_coef: 0.8151 - val_iou: 0.6903 - val_recall: 0.7597 - val_precision: 0.8963\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.19397 to 0.18625, saving model to files/inception_Unet_model.h5\n",
            "Epoch 12/30\n",
            "116/116 [==============================] - 43s 368ms/step - loss: 0.0796 - accuracy: 0.9971 - dice_coef: 0.9204 - iou: 0.8528 - recall: 0.9174 - precision: 0.9494 - val_loss: 0.1831 - val_accuracy: 0.9942 - val_dice_coef: 0.8182 - val_iou: 0.6949 - val_recall: 0.7760 - val_precision: 0.8841\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.18625 to 0.18312, saving model to files/inception_Unet_model.h5\n",
            "Epoch 13/30\n",
            "116/116 [==============================] - 43s 371ms/step - loss: 0.0795 - accuracy: 0.9970 - dice_coef: 0.9205 - iou: 0.8529 - recall: 0.9150 - precision: 0.9478 - val_loss: 0.1793 - val_accuracy: 0.9942 - val_dice_coef: 0.8217 - val_iou: 0.6991 - val_recall: 0.7917 - val_precision: 0.8708\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.18312 to 0.17929, saving model to files/inception_Unet_model.h5\n",
            "Epoch 14/30\n",
            "116/116 [==============================] - 43s 366ms/step - loss: 0.0761 - accuracy: 0.9971 - dice_coef: 0.9239 - iou: 0.8588 - recall: 0.9192 - precision: 0.9483 - val_loss: 0.1847 - val_accuracy: 0.9943 - val_dice_coef: 0.8166 - val_iou: 0.6925 - val_recall: 0.7444 - val_precision: 0.9069\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.17929\n",
            "Epoch 15/30\n",
            "116/116 [==============================] - 44s 376ms/step - loss: 0.0730 - accuracy: 0.9971 - dice_coef: 0.9270 - iou: 0.8642 - recall: 0.9201 - precision: 0.9505 - val_loss: 0.1873 - val_accuracy: 0.9941 - val_dice_coef: 0.8139 - val_iou: 0.6884 - val_recall: 0.7470 - val_precision: 0.8941\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.17929\n",
            "Epoch 16/30\n",
            "116/116 [==============================] - 44s 382ms/step - loss: 0.0684 - accuracy: 0.9973 - dice_coef: 0.9315 - iou: 0.8721 - recall: 0.9214 - precision: 0.9564 - val_loss: 0.1726 - val_accuracy: 0.9942 - val_dice_coef: 0.8285 - val_iou: 0.7097 - val_recall: 0.8107 - val_precision: 0.8553\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.17929 to 0.17262, saving model to files/inception_Unet_model.h5\n",
            "Epoch 17/30\n",
            "116/116 [==============================] - 44s 375ms/step - loss: 0.0671 - accuracy: 0.9973 - dice_coef: 0.9329 - iou: 0.8745 - recall: 0.9219 - precision: 0.9571 - val_loss: 0.1718 - val_accuracy: 0.9939 - val_dice_coef: 0.8293 - val_iou: 0.7104 - val_recall: 0.8515 - val_precision: 0.8245\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.17262 to 0.17180, saving model to files/inception_Unet_model.h5\n",
            "Epoch 18/30\n",
            "116/116 [==============================] - 42s 359ms/step - loss: 0.0652 - accuracy: 0.9973 - dice_coef: 0.9348 - iou: 0.8778 - recall: 0.9231 - precision: 0.9584 - val_loss: 0.1775 - val_accuracy: 0.9940 - val_dice_coef: 0.8237 - val_iou: 0.7026 - val_recall: 0.8080 - val_precision: 0.8545\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.17180\n",
            "Epoch 19/30\n",
            "116/116 [==============================] - 42s 364ms/step - loss: 0.0602 - accuracy: 0.9975 - dice_coef: 0.9398 - iou: 0.8867 - recall: 0.9281 - precision: 0.9630 - val_loss: 0.1668 - val_accuracy: 0.9944 - val_dice_coef: 0.8344 - val_iou: 0.7181 - val_recall: 0.7936 - val_precision: 0.8835\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.17180 to 0.16681, saving model to files/inception_Unet_model.h5\n",
            "Epoch 20/30\n",
            "116/116 [==============================] - 43s 368ms/step - loss: 0.0577 - accuracy: 0.9976 - dice_coef: 0.9423 - iou: 0.8912 - recall: 0.9313 - precision: 0.9640 - val_loss: 0.1726 - val_accuracy: 0.9943 - val_dice_coef: 0.8287 - val_iou: 0.7101 - val_recall: 0.7829 - val_precision: 0.8762\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.16681\n",
            "Epoch 21/30\n",
            "116/116 [==============================] - 41s 355ms/step - loss: 0.0556 - accuracy: 0.9976 - dice_coef: 0.9444 - iou: 0.8949 - recall: 0.9326 - precision: 0.9660 - val_loss: 0.1763 - val_accuracy: 0.9942 - val_dice_coef: 0.8248 - val_iou: 0.7046 - val_recall: 0.7679 - val_precision: 0.8853\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.16681\n",
            "Epoch 22/30\n",
            "116/116 [==============================] - 42s 357ms/step - loss: 0.0542 - accuracy: 0.9976 - dice_coef: 0.9459 - iou: 0.8975 - recall: 0.9334 - precision: 0.9671 - val_loss: 0.1753 - val_accuracy: 0.9942 - val_dice_coef: 0.8257 - val_iou: 0.7054 - val_recall: 0.7662 - val_precision: 0.8898\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.16681\n",
            "Epoch 23/30\n",
            "116/116 [==============================] - 41s 354ms/step - loss: 0.0526 - accuracy: 0.9977 - dice_coef: 0.9474 - iou: 0.9003 - recall: 0.9350 - precision: 0.9680 - val_loss: 0.1701 - val_accuracy: 0.9943 - val_dice_coef: 0.8311 - val_iou: 0.7134 - val_recall: 0.7861 - val_precision: 0.8788\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.16681\n",
            "Epoch 24/30\n",
            "116/116 [==============================] - 43s 370ms/step - loss: 0.0512 - accuracy: 0.9977 - dice_coef: 0.9488 - iou: 0.9027 - recall: 0.9351 - precision: 0.9695 - val_loss: 0.1627 - val_accuracy: 0.9944 - val_dice_coef: 0.8384 - val_iou: 0.7243 - val_recall: 0.8092 - val_precision: 0.8707\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.16681 to 0.16273, saving model to files/inception_Unet_model.h5\n",
            "Epoch 25/30\n",
            "116/116 [==============================] - 41s 349ms/step - loss: 0.0509 - accuracy: 0.9977 - dice_coef: 0.9491 - iou: 0.9033 - recall: 0.9354 - precision: 0.9696 - val_loss: 0.1748 - val_accuracy: 0.9943 - val_dice_coef: 0.8265 - val_iou: 0.7067 - val_recall: 0.7665 - val_precision: 0.8948\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.16273\n",
            "Epoch 26/30\n",
            "116/116 [==============================] - 41s 356ms/step - loss: 0.0488 - accuracy: 0.9978 - dice_coef: 0.9512 - iou: 0.9071 - recall: 0.9373 - precision: 0.9712 - val_loss: 0.1751 - val_accuracy: 0.9944 - val_dice_coef: 0.8263 - val_iou: 0.7067 - val_recall: 0.7405 - val_precision: 0.9217\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.16273\n",
            "Epoch 27/30\n",
            "116/116 [==============================] - 42s 360ms/step - loss: 0.0478 - accuracy: 0.9978 - dice_coef: 0.9522 - iou: 0.9089 - recall: 0.9377 - precision: 0.9721 - val_loss: 0.1681 - val_accuracy: 0.9942 - val_dice_coef: 0.8332 - val_iou: 0.7166 - val_recall: 0.8069 - val_precision: 0.8586\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.16273\n",
            "Epoch 28/30\n",
            "116/116 [==============================] - 42s 364ms/step - loss: 0.0459 - accuracy: 0.9979 - dice_coef: 0.9541 - iou: 0.9124 - recall: 0.9388 - precision: 0.9743 - val_loss: 0.1701 - val_accuracy: 0.9939 - val_dice_coef: 0.8309 - val_iou: 0.7130 - val_recall: 0.8541 - val_precision: 0.8174\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.16273\n",
            "Epoch 29/30\n",
            "116/116 [==============================] - 42s 357ms/step - loss: 0.0464 - accuracy: 0.9979 - dice_coef: 0.9536 - iou: 0.9115 - recall: 0.9381 - precision: 0.9736 - val_loss: 0.1663 - val_accuracy: 0.9943 - val_dice_coef: 0.8346 - val_iou: 0.7187 - val_recall: 0.8115 - val_precision: 0.8638\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.16273\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 30/30\n",
            "116/116 [==============================] - 41s 351ms/step - loss: 0.0403 - accuracy: 0.9981 - dice_coef: 0.9597 - iou: 0.9226 - recall: 0.9484 - precision: 0.9770 - val_loss: 0.1621 - val_accuracy: 0.9945 - val_dice_coef: 0.8391 - val_iou: 0.7253 - val_recall: 0.7987 - val_precision: 0.8814\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.16273 to 0.16206, saving model to files/inception_Unet_model.h5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52510b39a0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patoolib.extract_archive('SOMC_Seg.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "mEQrxfsG7lA8",
        "outputId": "aea32636-193c-4e4e-c934-1dd66b0f7b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting SOMC_Seg.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_7hs9spw8 -- SOMC_Seg.zip\n",
            "patool: ... SOMC_Seg.zip extracted to `SOMC_Seg'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SOMC_Seg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/files/inception_Unet_model.h5\",\"/content/drive/MyDrive/Tumor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YLAeu4Te74g6",
        "outputId": "3329a6b2-750c-461f-ae74-395484b9b6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Tumor/inception_Unet_model.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        " \n",
        "if __name__ == \"__main__\":\n",
        " \n",
        "    \"\"\" Loading model \"\"\"\n",
        "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
        "        model = tf.keras.models.load_model(\"/content/files/inception_Unet_model.h5\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    path = \"/content/SOMC_Seg/MRI_SOMC\"\n",
        "    test=sorted(glob(os.path.join(path, \"*.png\")))\n",
        "    create_dir(\"Output\")\n",
        "\n",
        "    \"\"\" Predicting the mask \"\"\"\n",
        "    for x in tqdm( test, total=len(test )):\n",
        "        \"\"\" Extracing the image name. \"\"\"\n",
        "        image_name = x.split(\"/\")[-1]\n",
        "\n",
        "        \"\"\" Reading the image \"\"\"\n",
        "        img = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (W, H))\n",
        "        x = img/255.0\n",
        "        x = x.astype(np.float32)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        \"\"\" Predicting the mask. \"\"\"\n",
        "        y_pred = model.predict(x)[0] > 0.5\n",
        "        print(type(y_pred))\n",
        "        y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "        \"\"\" Saving the predicted mask along with the image and GT \"\"\"\n",
        "        save_image_path = f\"/content/Output/{image_name}\"\n",
        "        y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
        "\n",
        "\n",
        "        output_image = np.concatenate([y_pred*255], axis=1)\n",
        "        cv2.imwrite(save_image_path, output_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYdbFd7I8EfL",
        "outputId": "e34bbfd4-8ead-4e38-83de-704828a6e9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 2/20 [00:02<00:15,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 6/20 [00:02<00:03,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:02<00:02,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 12/20 [00:02<00:00,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:02<00:00,  9.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 18/20 [00:03<00:00, 10.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:03<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Output.zip  /content/Output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUgKU4LF8TBO",
        "outputId": "1d98ed30-6df9-43a7-a678-762b843cd9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Output/ (stored 0%)\n",
            "  adding: content/Output/3069.png (deflated 60%)\n",
            "  adding: content/Output/3077.png (deflated 53%)\n",
            "  adding: content/Output/3068.png (deflated 58%)\n",
            "  adding: content/Output/3082.png (deflated 44%)\n",
            "  adding: content/Output/3084.png (deflated 48%)\n",
            "  adding: content/Output/3067.png (deflated 57%)\n",
            "  adding: content/Output/3083.png (deflated 47%)\n",
            "  adding: content/Output/3075.png (deflated 51%)\n",
            "  adding: content/Output/3080.png (deflated 45%)\n",
            "  adding: content/Output/3074.png (deflated 58%)\n",
            "  adding: content/Output/3081.png (deflated 43%)\n",
            "  adding: content/Output/3076.png (deflated 47%)\n",
            "  adding: content/Output/3079.png (deflated 42%)\n",
            "  adding: content/Output/3071.png (deflated 49%)\n",
            "  adding: content/Output/3072.png (deflated 44%)\n",
            "  adding: content/Output/3073.png (deflated 43%)\n",
            "  adding: content/Output/3066.png (deflated 60%)\n",
            "  adding: content/Output/3078.png (deflated 50%)\n",
            "  adding: content/Output/3065.png (deflated 56%)\n",
            "  adding: content/Output/3070.png (deflated 60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/Output.zip\",\"/content/drive/MyDrive/Tumor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J0dPKqxG8VkJ",
        "outputId": "1d9db609-3ea0-45f1-d812-f9777a5330c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Tumor/Output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"/content/files/inception_UNET_data.csv\",\"/content/drive/MyDrive/Tumor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dLuKdzxt8X0z",
        "outputId": "f03b3988-9ce0-4745-8c55-3b2345d0eec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Tumor/inception_UNET_data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "\n",
        "path1 = \"/content/SOMC_Seg/Mask_SOMC\"\n",
        "path2 = \"/content/Output\"\n",
        "Original=sorted(glob(os.path.join(path1, \"*.png\")))\n",
        "Output=sorted(glob(os.path.join(path2, \"*.png\")))\n",
        "\n",
        "for x, y  in tqdm(zip(Original,Output), total=len(Output)):\n",
        "    print(\"\\n\")\n",
        "    image_name = x.split(\"/\")[-1]\n",
        "    image_name2 = y.split(\"/\")[-1]\n",
        "    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
        "    x = cv2.resize(x, (W, H))   ## (h, w)\n",
        "    x = x / 255.0               ## (h, w)\n",
        "    x = x.astype(np.float32)    ## (h, w)\n",
        "    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n",
        "    \n",
        "    y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
        "    y = cv2.resize(y, (W, H))   ## (h, w)\n",
        "    y = y / 255.0               ## (h, w)\n",
        "    y = y.astype(np.float32)    ## (h, w)\n",
        "    y = np.expand_dims(y, axis=-1)## (h, w, 1)\n",
        "    \n",
        "\n",
        "    print(f\"For image {image_name} and image {image_name2} the Dice Coef is = {dice_coef(x,y)}\")\n",
        "    print(f\"For image {image_name} and image {image_name2} the IOU is = {iou(x,y)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSaahAJXB1dU",
        "outputId": "d26b2558-b3ce-4749-a75a-858a64af6103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 156.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "For image 3065.png and image 3065.png the Dice Coef is = 3.497865569078486e-19\n",
            "For image 3065.png and image 3065.png the IOU is = 3.497865569078486e-19\n",
            "\n",
            "\n",
            "For image 3066.png and image 3066.png the Dice Coef is = 0.9702081680297852\n",
            "For image 3066.png and image 3066.png the IOU is = 0.9421399235725403\n",
            "\n",
            "\n",
            "For image 3067.png and image 3067.png the Dice Coef is = 0.9141136407852173\n",
            "For image 3067.png and image 3067.png the IOU is = 0.8418133854866028\n",
            "\n",
            "\n",
            "For image 3068.png and image 3068.png the Dice Coef is = 0.9186642169952393\n",
            "For image 3068.png and image 3068.png the IOU is = 0.8495641350746155\n",
            "\n",
            "\n",
            "For image 3069.png and image 3069.png the Dice Coef is = 0.9655382633209229\n",
            "For image 3069.png and image 3069.png the IOU is = 0.9333727955818176\n",
            "\n",
            "\n",
            "For image 3070.png and image 3070.png the Dice Coef is = 0.9625996351242065\n",
            "For image 3070.png and image 3070.png the IOU is = 0.9278960227966309\n",
            "\n",
            "\n",
            "For image 3071.png and image 3071.png the Dice Coef is = 0.9783216714859009\n",
            "For image 3071.png and image 3071.png the IOU is = 0.9575634598731995\n",
            "\n",
            "\n",
            "For image 3072.png and image 3072.png the Dice Coef is = 0.972306489944458\n",
            "For image 3072.png and image 3072.png the IOU is = 0.9461055397987366\n",
            "\n",
            "\n",
            "For image 3073.png and image 3073.png the Dice Coef is = 0.9670934677124023\n",
            "For image 3073.png and image 3073.png the IOU is = 0.9362838864326477\n",
            "\n",
            "\n",
            "For image 3074.png and image 3074.png the Dice Coef is = 0.9198814630508423\n",
            "For image 3074.png and image 3074.png the IOU is = 0.8516486287117004\n",
            "\n",
            "\n",
            "For image 3075.png and image 3075.png the Dice Coef is = 0.7842428088188171\n",
            "For image 3075.png and image 3075.png the IOU is = 0.6450653076171875\n",
            "\n",
            "\n",
            "For image 3076.png and image 3076.png the Dice Coef is = 0.9596544504165649\n",
            "For image 3076.png and image 3076.png the IOU is = 0.9224383234977722\n",
            "\n",
            "\n",
            "For image 3077.png and image 3077.png the Dice Coef is = 0.9270220398902893\n",
            "For image 3077.png and image 3077.png the IOU is = 0.8639711737632751\n",
            "\n",
            "\n",
            "For image 3078.png and image 3078.png the Dice Coef is = 0.9602988958358765\n",
            "For image 3078.png and image 3078.png the IOU is = 0.923629879951477\n",
            "\n",
            "\n",
            "For image 3079.png and image 3079.png the Dice Coef is = 0.964348554611206\n",
            "For image 3079.png and image 3079.png the IOU is = 0.9311516284942627\n",
            "\n",
            "\n",
            "For image 3080.png and image 3080.png the Dice Coef is = 0.982357919216156\n",
            "For image 3080.png and image 3080.png the IOU is = 0.9653276801109314\n",
            "\n",
            "\n",
            "For image 3081.png and image 3081.png the Dice Coef is = 0.9822053909301758\n",
            "For image 3081.png and image 3081.png the IOU is = 0.9650330543518066\n",
            "\n",
            "\n",
            "For image 3082.png and image 3082.png the Dice Coef is = 0.9771592020988464\n",
            "For image 3082.png and image 3082.png the IOU is = 0.9553382992744446\n",
            "\n",
            "\n",
            "For image 3083.png and image 3083.png the Dice Coef is = 0.49334102869033813\n",
            "For image 3083.png and image 3083.png the IOU is = 0.32744041085243225\n",
            "\n",
            "\n",
            "For image 3084.png and image 3084.png the Dice Coef is = 0.9447317123413086\n",
            "For image 3084.png and image 3084.png the IOU is = 0.8952527642250061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyUtTdiSCSUK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}